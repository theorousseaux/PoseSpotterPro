{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_sequence_path = '../../../Data/Fall/Dataset_CAUCAFall/Poses_sequences/'\n",
    "list_of_files = os.listdir(poses_sequence_path)\n",
    "list_of_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_nose</th>\n",
       "      <th>Y_nose</th>\n",
       "      <th>X_left_eye</th>\n",
       "      <th>Y_left_eye</th>\n",
       "      <th>X_right_eye</th>\n",
       "      <th>Y_right_eye</th>\n",
       "      <th>X_left_ear</th>\n",
       "      <th>Y_left_ear</th>\n",
       "      <th>X_right_ear</th>\n",
       "      <th>Y_right_ear</th>\n",
       "      <th>...</th>\n",
       "      <th>Y_right_hip</th>\n",
       "      <th>X_left_knee</th>\n",
       "      <th>Y_left_knee</th>\n",
       "      <th>X_right_knee</th>\n",
       "      <th>Y_right_knee</th>\n",
       "      <th>X_left_ankle</th>\n",
       "      <th>Y_left_ankle</th>\n",
       "      <th>X_right_ankle</th>\n",
       "      <th>Y_right_ankle</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169.143264</td>\n",
       "      <td>185.373735</td>\n",
       "      <td>166.848344</td>\n",
       "      <td>180.783895</td>\n",
       "      <td>166.848344</td>\n",
       "      <td>178.488975</td>\n",
       "      <td>172.011914</td>\n",
       "      <td>176.767784</td>\n",
       "      <td>187.502626</td>\n",
       "      <td>160.129613</td>\n",
       "      <td>...</td>\n",
       "      <td>241.599281</td>\n",
       "      <td>255.202773</td>\n",
       "      <td>310.446889</td>\n",
       "      <td>272.414675</td>\n",
       "      <td>290.366337</td>\n",
       "      <td>274.135865</td>\n",
       "      <td>354.050373</td>\n",
       "      <td>285.610466</td>\n",
       "      <td>328.232521</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179.250105</td>\n",
       "      <td>168.874884</td>\n",
       "      <td>178.000106</td>\n",
       "      <td>163.874887</td>\n",
       "      <td>178.625106</td>\n",
       "      <td>161.999889</td>\n",
       "      <td>184.875102</td>\n",
       "      <td>163.249888</td>\n",
       "      <td>205.500089</td>\n",
       "      <td>148.874897</td>\n",
       "      <td>...</td>\n",
       "      <td>252.624832</td>\n",
       "      <td>256.750057</td>\n",
       "      <td>309.499797</td>\n",
       "      <td>273.625047</td>\n",
       "      <td>292.624808</td>\n",
       "      <td>273.625047</td>\n",
       "      <td>352.624771</td>\n",
       "      <td>285.500039</td>\n",
       "      <td>329.499785</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.922243</td>\n",
       "      <td>168.069931</td>\n",
       "      <td>180.294801</td>\n",
       "      <td>162.422954</td>\n",
       "      <td>180.922243</td>\n",
       "      <td>161.168071</td>\n",
       "      <td>187.196661</td>\n",
       "      <td>162.422954</td>\n",
       "      <td>209.784566</td>\n",
       "      <td>147.364351</td>\n",
       "      <td>...</td>\n",
       "      <td>254.029460</td>\n",
       "      <td>257.470145</td>\n",
       "      <td>310.499224</td>\n",
       "      <td>273.783632</td>\n",
       "      <td>292.303411</td>\n",
       "      <td>273.783632</td>\n",
       "      <td>353.165268</td>\n",
       "      <td>285.705027</td>\n",
       "      <td>329.949920</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.909204</td>\n",
       "      <td>167.881737</td>\n",
       "      <td>180.269556</td>\n",
       "      <td>162.764552</td>\n",
       "      <td>181.548852</td>\n",
       "      <td>159.566312</td>\n",
       "      <td>187.305685</td>\n",
       "      <td>164.043849</td>\n",
       "      <td>209.053718</td>\n",
       "      <td>146.773352</td>\n",
       "      <td>...</td>\n",
       "      <td>254.234222</td>\n",
       "      <td>257.666969</td>\n",
       "      <td>310.523249</td>\n",
       "      <td>274.297818</td>\n",
       "      <td>293.252752</td>\n",
       "      <td>273.658170</td>\n",
       "      <td>352.740019</td>\n",
       "      <td>285.171834</td>\n",
       "      <td>329.712690</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.269733</td>\n",
       "      <td>165.962793</td>\n",
       "      <td>181.630085</td>\n",
       "      <td>160.845608</td>\n",
       "      <td>182.269733</td>\n",
       "      <td>157.647368</td>\n",
       "      <td>188.666214</td>\n",
       "      <td>162.124904</td>\n",
       "      <td>211.693543</td>\n",
       "      <td>145.494055</td>\n",
       "      <td>...</td>\n",
       "      <td>254.234222</td>\n",
       "      <td>257.108554</td>\n",
       "      <td>310.523249</td>\n",
       "      <td>273.739403</td>\n",
       "      <td>292.613104</td>\n",
       "      <td>273.739403</td>\n",
       "      <td>353.379667</td>\n",
       "      <td>285.253067</td>\n",
       "      <td>328.433394</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X_nose      Y_nose  X_left_eye  Y_left_eye  X_right_eye  Y_right_eye  \\\n",
       "0  169.143264  185.373735  166.848344  180.783895   166.848344   178.488975   \n",
       "1  179.250105  168.874884  178.000106  163.874887   178.625106   161.999889   \n",
       "2  180.922243  168.069931  180.294801  162.422954   180.922243   161.168071   \n",
       "3  180.909204  167.881737  180.269556  162.764552   181.548852   159.566312   \n",
       "4  182.269733  165.962793  181.630085  160.845608   182.269733   157.647368   \n",
       "\n",
       "   X_left_ear  Y_left_ear  X_right_ear  Y_right_ear  ...  Y_right_hip  \\\n",
       "0  172.011914  176.767784   187.502626   160.129613  ...   241.599281   \n",
       "1  184.875102  163.249888   205.500089   148.874897  ...   252.624832   \n",
       "2  187.196661  162.422954   209.784566   147.364351  ...   254.029460   \n",
       "3  187.305685  164.043849   209.053718   146.773352  ...   254.234222   \n",
       "4  188.666214  162.124904   211.693543   145.494055  ...   254.234222   \n",
       "\n",
       "   X_left_knee  Y_left_knee  X_right_knee  Y_right_knee  X_left_ankle  \\\n",
       "0   255.202773   310.446889    272.414675    290.366337    274.135865   \n",
       "1   256.750057   309.499797    273.625047    292.624808    273.625047   \n",
       "2   257.470145   310.499224    273.783632    292.303411    273.783632   \n",
       "3   257.666969   310.523249    274.297818    293.252752    273.658170   \n",
       "4   257.108554   310.523249    273.739403    292.613104    273.739403   \n",
       "\n",
       "   Y_left_ankle  X_right_ankle  Y_right_ankle   label  \n",
       "0    354.050373     285.610466     328.232521  Normal  \n",
       "1    352.624771     285.500039     329.499785  Normal  \n",
       "2    353.165268     285.705027     329.949920  Normal  \n",
       "3    352.740019     285.171834     329.712690  Normal  \n",
       "4    353.379667     285.253067     328.433394  Normal  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(poses_sequence_path + list_of_files[0], index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        out, _ = self.rnn(x, h0.detach())\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test d'une passe forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(label):\n",
    "    if label == 'Normal':\n",
    "        return 0\n",
    "    elif label == 'Fall':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prétraitement des données\n",
    "sequence_length = 20\n",
    "num_features = 34  # Si chaque membre a des positions X et Y\n",
    "\n",
    "# Découper les séquences en fenêtres\n",
    "sequences = [df.iloc[i:i+sequence_length, :-1].values for i in range(len(df) - sequence_length + 1)]\n",
    "labels = [df['label'][i+sequence_length - 1] for i in range(len(df) - sequence_length + 1)]\n",
    "labels = [transform_labels(label) for label in labels]\n",
    "len(sequences), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([107, 20, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation\n",
    "for i in range(len(sequences)):\n",
    "    sequences[i] = (sequences[i] - sequences[i].mean()) / sequences[i].std()\n",
    "\n",
    "# Conversion en tenseurs PyTorch\n",
    "sequences = np.array(sequences)\n",
    "sequences_tensor = torch.tensor(sequences, dtype=torch.float32)\n",
    "sequences_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1023,  0.2418,  0.0149],\n",
       "        [ 0.1316,  0.2738,  0.0291],\n",
       "        [ 0.1268,  0.2846,  0.0201],\n",
       "        [ 0.1257,  0.3109, -0.0028],\n",
       "        [ 0.1062,  0.3364, -0.0570],\n",
       "        [ 0.1396,  0.2820,  0.0063],\n",
       "        [ 0.0640,  0.2887, -0.0810],\n",
       "        [ 0.1069,  0.3284, -0.0615],\n",
       "        [ 0.1171,  0.2489, -0.0300],\n",
       "        [ 0.1127,  0.2136, -0.0351],\n",
       "        [ 0.1470,  0.2492, -0.0489],\n",
       "        [ 0.1605,  0.2579, -0.0614],\n",
       "        [ 0.1561,  0.2575, -0.0577],\n",
       "        [ 0.1604,  0.2490, -0.0636],\n",
       "        [ 0.1605,  0.2564, -0.0738],\n",
       "        [ 0.1622,  0.2589, -0.0799],\n",
       "        [ 0.1553,  0.2695, -0.0983],\n",
       "        [ 0.1581,  0.2709, -0.0994],\n",
       "        [ 0.1537,  0.2644, -0.0988],\n",
       "        [ 0.1641,  0.2678, -0.1004],\n",
       "        [ 0.1659,  0.2647, -0.0996],\n",
       "        [ 0.1731,  0.2794, -0.1313],\n",
       "        [ 0.1732,  0.2714, -0.1332],\n",
       "        [ 0.1566,  0.2422, -0.1114],\n",
       "        [ 0.1514,  0.2442, -0.1166],\n",
       "        [ 0.1444,  0.2304, -0.1009],\n",
       "        [ 0.1478,  0.2441, -0.1055],\n",
       "        [ 0.1413,  0.2300, -0.0790],\n",
       "        [ 0.1514,  0.2338, -0.0619],\n",
       "        [ 0.1381,  0.2125, -0.0590],\n",
       "        [ 0.1540,  0.2012, -0.0770],\n",
       "        [ 0.1326,  0.1439, -0.0453],\n",
       "        [ 0.1574,  0.1856, -0.0276],\n",
       "        [ 0.1536,  0.2075, -0.0090],\n",
       "        [ 0.1477,  0.2429, -0.0278],\n",
       "        [ 0.1327,  0.2179,  0.0036],\n",
       "        [ 0.0864,  0.2019,  0.0279],\n",
       "        [ 0.1040,  0.2600, -0.0249],\n",
       "        [ 0.1163,  0.2533, -0.0326],\n",
       "        [ 0.1335,  0.1988, -0.0695],\n",
       "        [ 0.1648,  0.2267, -0.1449],\n",
       "        [ 0.1822,  0.2314, -0.1005],\n",
       "        [ 0.1651,  0.1763, -0.0936],\n",
       "        [ 0.1398,  0.1164, -0.1661],\n",
       "        [ 0.1539,  0.1052, -0.1821],\n",
       "        [ 0.1609,  0.1111, -0.2153],\n",
       "        [ 0.1465,  0.0790, -0.2108],\n",
       "        [ 0.1377,  0.0372, -0.1925],\n",
       "        [ 0.1544,  0.1054, -0.2556],\n",
       "        [ 0.1433,  0.0182, -0.1962],\n",
       "        [ 0.1357,  0.0351, -0.2597],\n",
       "        [ 0.1624,  0.0563, -0.2545],\n",
       "        [ 0.1560,  0.0329, -0.2570],\n",
       "        [ 0.1564,  0.0455, -0.2687],\n",
       "        [ 0.1687,  0.0623, -0.2731],\n",
       "        [ 0.1603,  0.0543, -0.2737],\n",
       "        [ 0.1611,  0.0722, -0.2959],\n",
       "        [ 0.1532,  0.0768, -0.2952],\n",
       "        [ 0.1562,  0.0649, -0.3296],\n",
       "        [ 0.1562,  0.0761, -0.3486],\n",
       "        [ 0.1644,  0.0738, -0.3674],\n",
       "        [ 0.1702,  0.0617, -0.3510],\n",
       "        [ 0.1736,  0.0679, -0.3495],\n",
       "        [ 0.1873,  0.0784, -0.3634],\n",
       "        [ 0.1848,  0.0697, -0.3622],\n",
       "        [ 0.1857,  0.0682, -0.3672],\n",
       "        [ 0.1922,  0.0717, -0.3741],\n",
       "        [ 0.1897,  0.0763, -0.3860],\n",
       "        [ 0.1875,  0.0639, -0.3929],\n",
       "        [ 0.1910,  0.0593, -0.3903],\n",
       "        [ 0.1861,  0.0579, -0.3956],\n",
       "        [ 0.1928,  0.0569, -0.3974],\n",
       "        [ 0.1904,  0.0572, -0.3966],\n",
       "        [ 0.1915,  0.0534, -0.3980],\n",
       "        [ 0.1839,  0.0490, -0.3989],\n",
       "        [ 0.1857,  0.0481, -0.4078],\n",
       "        [ 0.1882,  0.0462, -0.4019],\n",
       "        [ 0.1852,  0.0420, -0.4054],\n",
       "        [ 0.1836,  0.0391, -0.4093],\n",
       "        [ 0.1859,  0.0376, -0.4147],\n",
       "        [ 0.1850,  0.0363, -0.4189],\n",
       "        [ 0.1894,  0.0410, -0.4095],\n",
       "        [ 0.1935,  0.0474, -0.4062],\n",
       "        [ 0.1858,  0.0340, -0.4171],\n",
       "        [ 0.1902,  0.0420, -0.4148],\n",
       "        [ 0.1882,  0.0349, -0.4159],\n",
       "        [ 0.1875,  0.0343, -0.4219],\n",
       "        [ 0.1912,  0.0450, -0.4060],\n",
       "        [ 0.1890,  0.0448, -0.4107],\n",
       "        [ 0.1876,  0.0361, -0.4153],\n",
       "        [ 0.1875,  0.0379, -0.4106],\n",
       "        [ 0.1912,  0.0422, -0.4151],\n",
       "        [ 0.1865,  0.0359, -0.4173],\n",
       "        [ 0.1921,  0.0410, -0.4176],\n",
       "        [ 0.1933,  0.0438, -0.4146],\n",
       "        [ 0.1907,  0.0422, -0.4180],\n",
       "        [ 0.1873,  0.0375, -0.4229],\n",
       "        [ 0.1904,  0.0385, -0.4218],\n",
       "        [ 0.1946,  0.0429, -0.4192],\n",
       "        [ 0.1879,  0.0421, -0.4240],\n",
       "        [ 0.1956,  0.0396, -0.4181],\n",
       "        [ 0.1965,  0.0467, -0.4145],\n",
       "        [ 0.1868,  0.0452, -0.4167],\n",
       "        [ 0.1908,  0.0393, -0.4172],\n",
       "        [ 0.1911,  0.0399, -0.4186],\n",
       "        [ 0.1897,  0.0410, -0.4149],\n",
       "        [ 0.1944,  0.0423, -0.4152]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RNNClassifier(input_size=num_features, hidden_size=32, num_layers=2, num_classes=3)\n",
    "classifier(sequences_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1023,  0.2418,  0.0149],\n",
       "        [ 0.1316,  0.2738,  0.0291],\n",
       "        [ 0.1268,  0.2846,  0.0201],\n",
       "        [ 0.1257,  0.3109, -0.0028],\n",
       "        [ 0.1062,  0.3364, -0.0570],\n",
       "        [ 0.1396,  0.2820,  0.0063],\n",
       "        [ 0.0640,  0.2887, -0.0810],\n",
       "        [ 0.1069,  0.3284, -0.0615],\n",
       "        [ 0.1171,  0.2489, -0.0300],\n",
       "        [ 0.1127,  0.2136, -0.0351],\n",
       "        [ 0.1470,  0.2492, -0.0489],\n",
       "        [ 0.1605,  0.2579, -0.0614],\n",
       "        [ 0.1561,  0.2575, -0.0577],\n",
       "        [ 0.1604,  0.2490, -0.0636],\n",
       "        [ 0.1605,  0.2564, -0.0738],\n",
       "        [ 0.1622,  0.2589, -0.0799],\n",
       "        [ 0.1553,  0.2695, -0.0983],\n",
       "        [ 0.1581,  0.2709, -0.0994],\n",
       "        [ 0.1537,  0.2644, -0.0988],\n",
       "        [ 0.1641,  0.2678, -0.1004],\n",
       "        [ 0.1659,  0.2647, -0.0996],\n",
       "        [ 0.1731,  0.2794, -0.1313],\n",
       "        [ 0.1732,  0.2714, -0.1332],\n",
       "        [ 0.1566,  0.2422, -0.1114],\n",
       "        [ 0.1514,  0.2442, -0.1166],\n",
       "        [ 0.1444,  0.2304, -0.1009],\n",
       "        [ 0.1478,  0.2441, -0.1055],\n",
       "        [ 0.1413,  0.2300, -0.0790],\n",
       "        [ 0.1514,  0.2338, -0.0619],\n",
       "        [ 0.1381,  0.2125, -0.0590],\n",
       "        [ 0.1540,  0.2012, -0.0770],\n",
       "        [ 0.1326,  0.1439, -0.0453],\n",
       "        [ 0.1574,  0.1856, -0.0276],\n",
       "        [ 0.1536,  0.2075, -0.0090],\n",
       "        [ 0.1477,  0.2429, -0.0278],\n",
       "        [ 0.1327,  0.2179,  0.0036],\n",
       "        [ 0.0864,  0.2019,  0.0279],\n",
       "        [ 0.1040,  0.2600, -0.0249],\n",
       "        [ 0.1163,  0.2533, -0.0326],\n",
       "        [ 0.1335,  0.1988, -0.0695]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(sequences_tensor[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(label):\n",
    "    if label == 'Normal':\n",
    "        return 0\n",
    "    elif label == 'Fall':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  WalkS9.csvvsvv.csvvv\r"
     ]
    }
   ],
   "source": [
    "sequence_length = 20\n",
    "num_features = 34\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for file in list_of_files:\n",
    "    print(\"Processing file: \", file, end=\"\\r\")\n",
    "    df = pd.read_csv(poses_sequence_path + file, index_col=0)\n",
    "    for i in range(len(df) - sequence_length + 1):\n",
    "        seq = df.iloc[i:i+sequence_length, :-1].values\n",
    "        seq = (seq - seq.mean()) / seq.std()\n",
    "        sequences.append(seq)\n",
    "        labels.append(transform_labels(df['label'][i+sequence_length - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61276/3821212035.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  sequences_tensor = torch.tensor(sequences, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "sequences_tensor = torch.tensor(sequences, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18101, 20, 34])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sequences_tensor, labels_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 , loss:  1.0155349969863892\n",
      "Epoch:  1 , loss:  nan\n",
      "Epoch:  2 , loss:  0.9589605331420898\n",
      "Epoch:  3 , loss:  1.0564699172973633\n",
      "Epoch:  4 , loss:  1.011460781097412\n",
      "Epoch:  5 , loss:  0.9891057014465332\n",
      "Epoch:  6 , loss:  1.0225684642791748\n",
      "Epoch:  7 , loss:  1.0270195007324219\n",
      "Epoch:  8 , loss:  0.9875584840774536\n",
      "Epoch:  9 , loss:  0.9833074808120728\n",
      "Epoch:  10 , loss:  1.0450332164764404\n",
      "Epoch:  11 , loss:  0.9929062724113464\n",
      "Epoch:  12 , loss:  nan\n",
      "Epoch:  13 , loss:  1.0593966245651245\n",
      "Epoch:  14 , loss:  1.006899356842041\n",
      "Epoch:  15 , loss:  1.0235196352005005\n",
      "Epoch:  16 , loss:  1.032806634902954\n",
      "Epoch:  17 , loss:  1.0033601522445679\n",
      "Epoch:  18 , loss:  0.9984191656112671\n",
      "Epoch:  19 , loss:  1.014947772026062\n",
      "Epoch:  20 , loss:  1.0577119588851929\n",
      "Epoch:  21 , loss:  0.9445362091064453\n",
      "Epoch:  22 , loss:  1.0429261922836304\n",
      "Epoch:  23 , loss:  1.032084345817566\n",
      "Epoch:  24 , loss:  1.052648901939392\n",
      "Epoch:  25 , loss:  nan\n",
      "Epoch:  26 , loss:  1.0323525667190552\n",
      "Epoch:  27 , loss:  1.0213834047317505\n",
      "Epoch:  28 , loss:  1.01752507686615\n",
      "Epoch:  29 , loss:  1.0211989879608154\n",
      "Epoch:  30 , loss:  0.9745441675186157\n",
      "Epoch:  31 , loss:  0.9941977262496948\n",
      "Epoch:  32 , loss:  0.9860754013061523\n",
      "Epoch:  33 , loss:  nan\n",
      "Epoch:  34 , loss:  1.016594648361206\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m mini_batch_x, mini_batch_y \u001b[39m=\u001b[39m X_train[indices], y_train[indices]\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[39m=\u001b[39m classifier(mini_batch_x)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, mini_batch_y)\n\u001b[1;32m     16\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/PoseEstimation/posespotterpro/mmposevenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mRNNClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mrequires_grad_()\n\u001b[1;32m     14\u001b[0m out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(x, h0\u001b[39m.\u001b[39mdetach())\n\u001b[0;32m---> 15\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(out[:, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, :])\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/PoseEstimation/posespotterpro/mmposevenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PoseEstimation/posespotterpro/mmposevenv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "mini_batch_size = 16\n",
    "n_epochs = 100\n",
    "\n",
    "classifier = RNNClassifier(input_size=num_features, hidden_size=32, num_layers=2, num_classes=3)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    permutation = torch.randperm(X_train.size()[0])\n",
    "    for i in range(0, X_train.size()[0], mini_batch_size):\n",
    "        indices = permutation[i:i+mini_batch_size]\n",
    "        mini_batch_x, mini_batch_y = X_train[indices], y_train[indices]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(mini_batch_x)\n",
    "        loss = criterion(outputs, mini_batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Minibatch : ', i, ', loss: ', loss.item())\n",
    "    print('Epoch: ', epoch, ', loss: ', loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmposevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
