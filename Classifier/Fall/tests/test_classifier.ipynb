{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_sequence_path = '../../../Data/Fall/Dataset_CAUCAFall/Poses_sequences/'\n",
    "list_of_files = os.listdir(poses_sequence_path)\n",
    "list_of_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_nose</th>\n",
       "      <th>Y_nose</th>\n",
       "      <th>X_left_eye</th>\n",
       "      <th>Y_left_eye</th>\n",
       "      <th>X_right_eye</th>\n",
       "      <th>Y_right_eye</th>\n",
       "      <th>X_left_ear</th>\n",
       "      <th>Y_left_ear</th>\n",
       "      <th>X_right_ear</th>\n",
       "      <th>Y_right_ear</th>\n",
       "      <th>...</th>\n",
       "      <th>Y_right_hip</th>\n",
       "      <th>X_left_knee</th>\n",
       "      <th>Y_left_knee</th>\n",
       "      <th>X_right_knee</th>\n",
       "      <th>Y_right_knee</th>\n",
       "      <th>X_left_ankle</th>\n",
       "      <th>Y_left_ankle</th>\n",
       "      <th>X_right_ankle</th>\n",
       "      <th>Y_right_ankle</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169.143264</td>\n",
       "      <td>185.373735</td>\n",
       "      <td>166.848344</td>\n",
       "      <td>180.783895</td>\n",
       "      <td>166.848344</td>\n",
       "      <td>178.488975</td>\n",
       "      <td>172.011914</td>\n",
       "      <td>176.767784</td>\n",
       "      <td>187.502626</td>\n",
       "      <td>160.129613</td>\n",
       "      <td>...</td>\n",
       "      <td>241.599281</td>\n",
       "      <td>255.202773</td>\n",
       "      <td>310.446889</td>\n",
       "      <td>272.414675</td>\n",
       "      <td>290.366337</td>\n",
       "      <td>274.135865</td>\n",
       "      <td>354.050373</td>\n",
       "      <td>285.610466</td>\n",
       "      <td>328.232521</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179.250105</td>\n",
       "      <td>168.874884</td>\n",
       "      <td>178.000106</td>\n",
       "      <td>163.874887</td>\n",
       "      <td>178.625106</td>\n",
       "      <td>161.999889</td>\n",
       "      <td>184.875102</td>\n",
       "      <td>163.249888</td>\n",
       "      <td>205.500089</td>\n",
       "      <td>148.874897</td>\n",
       "      <td>...</td>\n",
       "      <td>252.624832</td>\n",
       "      <td>256.750057</td>\n",
       "      <td>309.499797</td>\n",
       "      <td>273.625047</td>\n",
       "      <td>292.624808</td>\n",
       "      <td>273.625047</td>\n",
       "      <td>352.624771</td>\n",
       "      <td>285.500039</td>\n",
       "      <td>329.499785</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.922243</td>\n",
       "      <td>168.069931</td>\n",
       "      <td>180.294801</td>\n",
       "      <td>162.422954</td>\n",
       "      <td>180.922243</td>\n",
       "      <td>161.168071</td>\n",
       "      <td>187.196661</td>\n",
       "      <td>162.422954</td>\n",
       "      <td>209.784566</td>\n",
       "      <td>147.364351</td>\n",
       "      <td>...</td>\n",
       "      <td>254.029460</td>\n",
       "      <td>257.470145</td>\n",
       "      <td>310.499224</td>\n",
       "      <td>273.783632</td>\n",
       "      <td>292.303411</td>\n",
       "      <td>273.783632</td>\n",
       "      <td>353.165268</td>\n",
       "      <td>285.705027</td>\n",
       "      <td>329.949920</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.909204</td>\n",
       "      <td>167.881737</td>\n",
       "      <td>180.269556</td>\n",
       "      <td>162.764552</td>\n",
       "      <td>181.548852</td>\n",
       "      <td>159.566312</td>\n",
       "      <td>187.305685</td>\n",
       "      <td>164.043849</td>\n",
       "      <td>209.053718</td>\n",
       "      <td>146.773352</td>\n",
       "      <td>...</td>\n",
       "      <td>254.234222</td>\n",
       "      <td>257.666969</td>\n",
       "      <td>310.523249</td>\n",
       "      <td>274.297818</td>\n",
       "      <td>293.252752</td>\n",
       "      <td>273.658170</td>\n",
       "      <td>352.740019</td>\n",
       "      <td>285.171834</td>\n",
       "      <td>329.712690</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.269733</td>\n",
       "      <td>165.962793</td>\n",
       "      <td>181.630085</td>\n",
       "      <td>160.845608</td>\n",
       "      <td>182.269733</td>\n",
       "      <td>157.647368</td>\n",
       "      <td>188.666214</td>\n",
       "      <td>162.124904</td>\n",
       "      <td>211.693543</td>\n",
       "      <td>145.494055</td>\n",
       "      <td>...</td>\n",
       "      <td>254.234222</td>\n",
       "      <td>257.108554</td>\n",
       "      <td>310.523249</td>\n",
       "      <td>273.739403</td>\n",
       "      <td>292.613104</td>\n",
       "      <td>273.739403</td>\n",
       "      <td>353.379667</td>\n",
       "      <td>285.253067</td>\n",
       "      <td>328.433394</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X_nose      Y_nose  X_left_eye  Y_left_eye  X_right_eye  Y_right_eye  \\\n",
       "0  169.143264  185.373735  166.848344  180.783895   166.848344   178.488975   \n",
       "1  179.250105  168.874884  178.000106  163.874887   178.625106   161.999889   \n",
       "2  180.922243  168.069931  180.294801  162.422954   180.922243   161.168071   \n",
       "3  180.909204  167.881737  180.269556  162.764552   181.548852   159.566312   \n",
       "4  182.269733  165.962793  181.630085  160.845608   182.269733   157.647368   \n",
       "\n",
       "   X_left_ear  Y_left_ear  X_right_ear  Y_right_ear  ...  Y_right_hip  \\\n",
       "0  172.011914  176.767784   187.502626   160.129613  ...   241.599281   \n",
       "1  184.875102  163.249888   205.500089   148.874897  ...   252.624832   \n",
       "2  187.196661  162.422954   209.784566   147.364351  ...   254.029460   \n",
       "3  187.305685  164.043849   209.053718   146.773352  ...   254.234222   \n",
       "4  188.666214  162.124904   211.693543   145.494055  ...   254.234222   \n",
       "\n",
       "   X_left_knee  Y_left_knee  X_right_knee  Y_right_knee  X_left_ankle  \\\n",
       "0   255.202773   310.446889    272.414675    290.366337    274.135865   \n",
       "1   256.750057   309.499797    273.625047    292.624808    273.625047   \n",
       "2   257.470145   310.499224    273.783632    292.303411    273.783632   \n",
       "3   257.666969   310.523249    274.297818    293.252752    273.658170   \n",
       "4   257.108554   310.523249    273.739403    292.613104    273.739403   \n",
       "\n",
       "   Y_left_ankle  X_right_ankle  Y_right_ankle   label  \n",
       "0    354.050373     285.610466     328.232521  Normal  \n",
       "1    352.624771     285.500039     329.499785  Normal  \n",
       "2    353.165268     285.705027     329.949920  Normal  \n",
       "3    352.740019     285.171834     329.712690  Normal  \n",
       "4    353.379667     285.253067     328.433394  Normal  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(poses_sequence_path + list_of_files[0], index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va entrainer un classifier sur des fenêtres glissantes des vidéos. On va donc créer une fonction qui va nous permettre de générer ces fenêtres glissantes. Ensuite pour chaque fenêtre on va extraire des caractéristiques pour ne pas avoir un nombre de features trop important. On va commencer par calculer, pour chaque fenêtre et chaque point clé, en x et en y, sa moyenne, son écart-type, sa valeur minimale et sa valeur maximale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des fenêtres glissantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sliding_windows(df, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Returns a list of dataframes of size window_size with step_size between each dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split into windows.\n",
    "        window_size (int): Size of each window.\n",
    "        step_size (int): Number of rows to skip between each window.\n",
    "        \n",
    "    Returns:\n",
    "        windows (list): List of dataframes of size window_size with step_size between each dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    windows = []\n",
    "    for i in range(0, len(df) - window_size, step_size):\n",
    "        windows.append(df[i:i+window_size])\n",
    "\n",
    "    print(\"Total number of frames:\", len(df))\n",
    "    print(\"Number of windows:\", len(windows))\n",
    "    \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_window(window):\n",
    "    \"\"\"\n",
    "    Extract features from a window of data. \n",
    "\n",
    "    Args:\n",
    "        window (np.array): A window of data\n",
    "\n",
    "    Returns:\n",
    "        features (dict): A dictionary of features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    for keypoint in window.columns:\n",
    "\n",
    "        if keypoint == 'label':\n",
    "            continue\n",
    "\n",
    "        features[keypoint + '_mean'] = window[keypoint].mean()\n",
    "        features[keypoint + '_std'] = window[keypoint].std()\n",
    "        features[keypoint + '_min'] = window[keypoint].min()\n",
    "        features[keypoint + '_max'] = window[keypoint].max()\n",
    "            \n",
    "    return features\n",
    "\n",
    "\n",
    "def create_dataset(windows):\n",
    "    \"\"\"\n",
    "    Create a dataset from a list of windows.\n",
    "\n",
    "    Args:\n",
    "        windows (list): A list of windows\n",
    "\n",
    "    Returns:\n",
    "        X (pd.DataFrame): A dataframe of features\n",
    "        y (np.array): An array of labels\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    window_labels = []\n",
    "    for window in windows:\n",
    "        features.append(get_features_from_window(window))\n",
    "        if 'Fall' in window['label'].values:\n",
    "            window_labels.append('Fall')\n",
    "        else:\n",
    "            window_labels.append(window['label'].iloc[-1])\n",
    "\n",
    "    return pd.DataFrame(features), np.array(window_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('../../../')\n",
    "sys.path.append(root_dir)\n",
    "from Classifier.Fall.data_preparation import WindowFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prepare_data() missing 1 required positional argument: 'files_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m step_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m      6\u001b[0m window_feature_extractor \u001b[39m=\u001b[39m WindowFeatureExtractor(window_size, step_size)\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[39m=\u001b[39m WindowFeatureExtractor\u001b[39m.\u001b[39;49mprepare_data(poses_sequence_path)\n",
      "\u001b[1;31mTypeError\u001b[0m: prepare_data() missing 1 required positional argument: 'files_list'"
     ]
    }
   ],
   "source": [
    "\n",
    "poses_sequence_path = '../../../Data/Fall/Dataset_CAUCAFall/Poses_sequences/'\n",
    "    \n",
    "window_size = 10\n",
    "step_size = 5\n",
    "\n",
    "window_feature_extractor = WindowFeatureExtractor(window_size, step_size)\n",
    "X, y = WindowFeatureExtractor.prepare_data(poses_sequence_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_frame_counts = []\n",
    "fall_frame_counts = []\n",
    "lying_frame_counts = []\n",
    "\n",
    "for file in list_of_files:\n",
    "    df = pd.read_csv(poses_sequence_path + file, index_col=0)\n",
    "    value_counts = df.label.value_counts()\n",
    "\n",
    "    normal_frame_counts.append(value_counts['Normal'])\n",
    "    if len(value_counts) > 1:\n",
    "        fall_frame_counts.append(value_counts['Fall'])\n",
    "        lying_frame_counts.append(value_counts['Lying down'])\n",
    "    else:\n",
    "        fall_frame_counts.append(0)\n",
    "        lying_frame_counts.append(0)\n",
    "    \n",
    "data = {'Normal': normal_frame_counts, 'Fall': fall_frame_counts, 'Lying down': lying_frame_counts}\n",
    "df = pd.DataFrame(data=data, index=list_of_files)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.histplot(df, ax=ax, kde=True, bins=20)\n",
    "ax.set_title('Distribution of the number of frames per video')\n",
    "ax.set_xlabel('Number of frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {'Fall': 1, 'Lying down': 1, 'Normal': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "labels = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0)\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "random_forest.score(X_test_scaled, y_test)\n",
    "print(\"Random Forest Accuracy: \", random_forest.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict(X_test_scaled)\n",
    "conf = confusion_matrix(y_test, y_pred, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix):\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='x-large')\n",
    "    \n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_yticklabels(labels, rotation=45)\n",
    "\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    \n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Ground Truth', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = 'RandomForest_WindowSize_{}_Step_{}'.format(window_size, step_size)\n",
    "pickle.dump(X_test_scaled, open(file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de Grid search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmposevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
